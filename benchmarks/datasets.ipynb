{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "import datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This is a modified version of https://github.com/serega/gaoya/blob/master/py-gaoya/examples/deduplication_scholarly_articles_gaoya.ipynb, which benchmarks the algorithm on \n",
    "the `pinecone/core-2020-05-10-deduplication` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration pinecone--core-2020-05-10-deduplication-dbaaf752a12c0b16\n",
      "Found cached dataset json (/Users/chenghao/.cache/huggingface/datasets/pinecone___json/pinecone--core-2020-05-10-deduplication-dbaaf752a12c0b16/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1465f00025b142f29b85ebfde2ae2e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4bf67f6f4bf4b8a9817eb2007b659ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the script\n",
    "\n",
    "ds = datasets.load_dataset(\"pinecone/core-2020-05-10-deduplication\", split=\"train\")\n",
    "ds = ds.map(lambda x: {\"text\": (x[\"processed_title\"] + \" \" + x[\"processed_abstract\"]).lower()})\n",
    "ds.save_to_disk(\"temp_inp\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no character shingle tokenizer in the script, you can either modify the code or use an n-gram tokenizer. For simplicity, we use bigrams in this example. Other parameters are the same as the original script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!python -m text_dedup.minhash --path ./temp_inp --local --column text --num_perm 200 --ngram 2 --threshold 0.5 --output temp --split train --debug --b 50 --r 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading                         : 0.00s  \n",
    "# MinHashing                      : 2.39s  \n",
    "# Clustering                      : 8.76s  \n",
    "# Filtering                       : 0.72s  \n",
    "# Saving                          : 10.13s \n",
    "# Total                           : 22.01s \n",
    "# Before                          : 100000 \n",
    "# After                           : 72135 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenghao/mambaforge/envs/text-dedup/lib/python3.10/site-packages/datasets/arrow_dataset.py:1533: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ds = datasets.load_from_disk(\"temp_inp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15340a929f84d8faf8565c83a7e630c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "truth = ds.map(lambda x, id: {\"core_id\": x[\"core_id\"], \"id\": id, \"duplicates\": x[\"labelled_duplicates\"]}, remove_columns=ds.column_names, with_indices=True)\n",
    "id2core_id = {x[\"id\"]: int(x[\"core_id\"]) for x in truth}\n",
    "labels = {int(x[\"core_id\"]): set(map(int, x[\"duplicates\"])) if x[\"duplicates\"] else set() for x in truth}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"temp/uf.pkl\", \"rb\") as f:\n",
    "    uf = pickle.load(f)\n",
    "\n",
    "id2cluster = defaultdict(set)\n",
    "for id, cluster in uf.parent.items():\n",
    "    id2cluster[cluster].add(id)\n",
    "\n",
    "predictions = {id2core_id[x[\"id\"]]: set([id2core_id[neighbor] for neighbor in id2cluster[uf.find(x[\"id\"])] if neighbor != x[\"id\"]]) for x in truth}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>duplicates</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11251086</td>\n",
       "      <td>{82332306}</td>\n",
       "      <td>{82332306}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11309751</td>\n",
       "      <td>{147599753}</td>\n",
       "      <td>{147599753}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11311385</td>\n",
       "      <td>{147603441}</td>\n",
       "      <td>{147603441}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11992240</td>\n",
       "      <td>{148653623}</td>\n",
       "      <td>{148653623}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11994990</td>\n",
       "      <td>{148656283}</td>\n",
       "      <td>{148656283}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index   duplicates  predictions\n",
       "0  11251086   {82332306}   {82332306}\n",
       "1  11309751  {147599753}  {147599753}\n",
       "2  11311385  {147603441}  {147603441}\n",
       "3  11992240  {148653623}  {148653623}\n",
       "4  11994990  {148656283}  {148656283}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.Series(labels).to_frame(\"duplicates\").reset_index().merge(pd.Series(predictions).to_frame(\"predictions\").reset_index(), on=\"index\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Correct'] = df.apply(lambda row: set(row['duplicates']) == set(row['predictions']), axis=1).astype(int)\n",
    "prediction_summary = { 'Correct' : df['Correct'].sum(), 'Incorrect' : df.shape[0] - df['Correct'].sum() }\n",
    "prediction_summary['Accuracy'] = round(prediction_summary['Correct'] / df.shape[0], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _recall(row):\n",
    "    labelled_dups = set(row['duplicates'])\n",
    "    if len(labelled_dups) == 0:\n",
    "        return 1\n",
    "    dups = set(row['predictions'])\n",
    "    return len(dups & labelled_dups) / len(labelled_dups)\n",
    "recalls = df.apply(lambda row: _recall(row), axis=1)\n",
    "prediction_summary['Recall'] = round(recalls.mean(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _precision(row):\n",
    "    labelled_dups = set(row['duplicates'])\n",
    "    dups = set(row['predictions'])    \n",
    "    if len(dups) == 0:\n",
    "        return 0\n",
    "\n",
    "    return len(dups & labelled_dups) / len(dups)\n",
    "precisions = df.apply(lambda row: _precision(row), axis=1)\n",
    "prediction_summary['Precision'] = round(precisions.mean(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Correct': 92389,\n",
       " 'Incorrect': 7611,\n",
       " 'Accuracy': 0.9239,\n",
       " 'Recall': 0.9651,\n",
       " 'Precision': 0.4432}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Deduplication of Scholarly Documents using Locality Sensitive Hashing and Word Embeddings](https://aclanthology.org/2020.lrec-1.113) (Gyawali et al., LREC 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9464, Recall: 0.9446, F1: 0.9455\n",
      "Precision: 0.9481, Recall: 0.9497, F1: 0.9489\n",
      "Macro Average F1: 0.9472\n"
     ]
    }
   ],
   "source": [
    "def classify_in_paper(record):\n",
    "    duplicates = set(record['duplicates'])\n",
    "    predictions = set(record['predictions'])\n",
    "\n",
    "    if len(predictions) == 0 and len(duplicates) > 0:\n",
    "        return 'FN'\n",
    "\n",
    "    if duplicates.issubset(predictions) and len(predictions) > 0 and len(duplicates) > 0:\n",
    "        return 'TP'\n",
    "    \n",
    "    if len(duplicates) == 0 and len(predictions) == 0:\n",
    "        return 'TN'\n",
    "    \n",
    "    if len(predictions) > 0:\n",
    "        if len(duplicates) == 0 or not duplicates.issubset(predictions):\n",
    "            return 'FP'\n",
    "    \n",
    "    raise ValueError(f'This should not happen {duplicates} {predictions} {len(duplicates)=} {len(predictions)=}')\n",
    "\n",
    "def inverse(label):\n",
    "    if label == 'TP':\n",
    "        return 'TN'\n",
    "    if label == 'FN':\n",
    "        return 'FP'\n",
    "    if label == 'FP':\n",
    "        return 'FN'\n",
    "    if label == 'TN':\n",
    "        return 'TP'\n",
    "\n",
    "df['Class'] = df.apply(lambda row: classify_in_paper(row), axis=1)\n",
    "df['Class_'] = df.apply(lambda row: inverse(row['Class']), axis=1)\n",
    "\n",
    "f1s = []\n",
    "for col in ['Class', 'Class_']:\n",
    "    label_counts = df[col].value_counts()\n",
    "    precision = label_counts['TP'] / (label_counts['TP'] + label_counts['FP'])\n",
    "    recall = label_counts['TP'] / (label_counts['TP'] + label_counts['FN'])\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')\n",
    "    f1s.append(f1)\n",
    "print(f'Macro Average F1: {sum(f1s) / len(f1s):.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers seem too good to be true compared with what we see in the paper. Let's double check their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2741039d31146749c407e339e3d6e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>predictions</th>\n",
       "      <th>duplicates</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Class</th>\n",
       "      <th>Class_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11251086</td>\n",
       "      <td>[82332306]</td>\n",
       "      <td>{82332306}</td>\n",
       "      <td>1</td>\n",
       "      <td>TP</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11309751</td>\n",
       "      <td>[147599753]</td>\n",
       "      <td>{147599753}</td>\n",
       "      <td>1</td>\n",
       "      <td>TP</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11311385</td>\n",
       "      <td>[147603441]</td>\n",
       "      <td>{147603441}</td>\n",
       "      <td>1</td>\n",
       "      <td>TP</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11992240</td>\n",
       "      <td>[148653623]</td>\n",
       "      <td>{148653623}</td>\n",
       "      <td>1</td>\n",
       "      <td>TP</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11994990</td>\n",
       "      <td>[148656283]</td>\n",
       "      <td>{148656283}</td>\n",
       "      <td>1</td>\n",
       "      <td>TP</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  predictions   duplicates  Correct Class Class_\n",
       "0  11251086   [82332306]   {82332306}        1    TP     TN\n",
       "1  11309751  [147599753]  {147599753}        1    TP     TN\n",
       "2  11311385  [147603441]  {147603441}        1    TP     TN\n",
       "3  11992240  [148653623]  {148653623}        1    TP     TN\n",
       "4  11994990  [148656283]  {148656283}        1    TP     TN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title2core_ids = defaultdict(set)\n",
    "for record in ds:\n",
    "    title = record['processed_title']\n",
    "    core_id = int(record['core_id'])\n",
    "    title2core_ids[title].add(core_id)\n",
    "\n",
    "matches = ds.map(lambda row: {'matches': set(x for x in title2core_ids[row[\"processed_title\"]] if x != int(row[\"core_id\"]))})\n",
    "matches = {int(x[\"core_id\"]): x[\"matches\"] for x in matches}\n",
    "\n",
    "ddf = pd.Series(matches).to_frame(\"predictions\").reset_index().merge(df.drop(\"predictions\", axis=1), on=\"index\")\n",
    "ddf[\"Correct\"] = ddf.apply(lambda row: set(row['duplicates']) == set(row['predictions']), axis=1).astype(int)\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8302, Recall: 0.5521, F1: 0.6632\n",
      "Precision: 0.7098, Recall: 0.9065, F1: 0.7962\n",
      "Macro Average F1: 0.7297, Accuracy: 0.7456\n"
     ]
    }
   ],
   "source": [
    "ddf['Class'] = ddf.apply(lambda row: classify_in_paper(row), axis=1)\n",
    "ddf['Class_'] = ddf.apply(lambda row: inverse(row['Class']), axis=1)\n",
    "\n",
    "f1s = []\n",
    "for col in ['Class', 'Class_']:\n",
    "    label_counts = ddf[col].value_counts()\n",
    "    precision = label_counts['TP'] / (label_counts['TP'] + label_counts['FP'])\n",
    "    recall = label_counts['TP'] / (label_counts['TP'] + label_counts['FN'])\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')\n",
    "    f1s.append(f1)\n",
    "print(f'Macro Average F1: {sum(f1s) / len(f1s):.4f}, Accuracy: {ddf[\"Correct\"].mean():.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is strange: precisions are the same as the paper, but recalls are not. Accuracy is also the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!rm -r temp_inp temp ../temp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-dedup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34b527130893b47044197df5fe15869983e660be4f2927608e2aeec6a74366e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
